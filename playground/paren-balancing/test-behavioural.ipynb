{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing behavioural performance of DAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE_CPU = False\n",
    "SEED = 2384\n",
    "MODEL_NAME = \"gelu-1l\"\n",
    "\n",
    "OPEN_PAREN_STR_TOKENS = [\"(\"]\n",
    "CLOSE_PAREN_STR_TOKENS = [\")\"]\n",
    "SUPPRESSING_STR_TOKENS = [\"(\", \"_\", \",\", \"+\", \".\"]\n",
    "\n",
    "DATA_FILES = {\n",
    "    \"single_line\": \"../../data/paren-balancing/single_line.csv\",\n",
    "    \"synthetic\": \"../../data/paren-balancing/synthetic_1.csv\",\n",
    "}\n",
    "\n",
    "SAVE_MODEL_PREDICTIONS = False\n",
    "LOAD_MODEL_PREDICTIONS = True\n",
    "MODEL_PREDICTIONS_DATA_FILE = \"../saved_data/model_predictions.pt\"\n",
    "\n",
    "DATASET_MAX_SIZE = 10000\n",
    "\n",
    "DAG_BATCH_SIZE = 10000\n",
    "MODEL_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import to_numpy\n",
    "\n",
    "from causal_networks.dag import (\n",
    "    DAGModel,\n",
    "    InputNode,\n",
    "    GreaterThanZeroNode,\n",
    "    InSetOutSetNode,\n",
    "    CumSumNode,\n",
    ")\n",
    "from causal_networks.predefined_models import make_basic_pb_dag\n",
    "from causal_networks.variable_alignment import TransformerVariableAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if not FORCE_CPU and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model, DAGs and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gelu-1l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(MODEL_NAME, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open paren tokens: [10]\n",
      "Closed paren tokens: [11]\n",
      "Suppressing tokens: [10, 65, 14, 13, 16]\n"
     ]
    }
   ],
   "source": [
    "open_paren_tokens = model.to_tokens(\n",
    "    OPEN_PAREN_STR_TOKENS, prepend_bos=False, move_to_device=False, truncate=False\n",
    ")\n",
    "open_paren_tokens = [\n",
    "    open_paren_tokens[i, 0].item() for i in range(open_paren_tokens.shape[0])\n",
    "]\n",
    "\n",
    "closed_paren_tokens = model.to_tokens(\n",
    "    CLOSE_PAREN_STR_TOKENS, prepend_bos=False, move_to_device=False, truncate=False\n",
    ")\n",
    "closed_paren_tokens = [\n",
    "    closed_paren_tokens[i, 0].item() for i in range(closed_paren_tokens.shape[0])\n",
    "]\n",
    "\n",
    "suppressing_tokens = model.to_tokens(\n",
    "    SUPPRESSING_STR_TOKENS, prepend_bos=False, move_to_device=False, truncate=False\n",
    ")\n",
    "suppressing_tokens = [\n",
    "    suppressing_tokens[i, 0].item() for i in range(suppressing_tokens.shape[0])\n",
    "]\n",
    "\n",
    "print(\"Open paren tokens:\", open_paren_tokens)\n",
    "print(\"Closed paren tokens:\", closed_paren_tokens)\n",
    "print(\"Suppressing tokens:\", suppressing_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_modifier(y: torch.tensor):\n",
    "    binary_output = torch.empty(*y.shape[:-1], 2, device=y.device)\n",
    "    binary_output[..., 0] = y[..., open_paren_tokens].sum(dim=-1)\n",
    "    binary_output[..., 1] = y[..., closed_paren_tokens].sum(dim=-1)\n",
    "    return F.softmax(binary_output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dags = {\"basic\": make_basic_pb_dag(model, device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                  Node Information                   </span>\n",
       "┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Node </span>┃<span style=\"font-weight: bold\"> Module                                     </span>┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x    │ InputNode()                                │\n",
       "│ v    │ InSetOutSetNode(in_set=[10], out_set=[11]) │\n",
       "│ s    │ CumSumNode(dim=-1)                         │\n",
       "│ c    │ GreaterThanZeroNode()                      │\n",
       "└──────┴────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                  Node Information                   \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mNode\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mModule                                    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x    │ InputNode()                                │\n",
       "│ v    │ InSetOutSetNode(in_set=[10], out_set=[11]) │\n",
       "│ s    │ CumSumNode(dim=-1)                         │\n",
       "│ c    │ GreaterThanZeroNode()                      │\n",
       "└──────┴────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, dag in dags.items():\n",
    "    dag.visualize(display_node_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1f77f\">\n",
       "  <caption>single_line</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1f77f_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1f77f_level0_row0\" class=\"row_heading level0 row0\" >289</th>\n",
       "      <td id=\"T_1f77f_row0_col0\" class=\"data row0 col0\" >        grad_d = load(grad_d_file).2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f77f_level0_row1\" class=\"row_heading level0 row1\" >18605</th>\n",
       "      <td id=\"T_1f77f_row1_col0\" class=\"data row1 col0\" >        melt_value_vars = [c for c in df.columns if re.search(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f77f_level0_row2\" class=\"row_heading level0 row2\" >112171</th>\n",
       "      <td id=\"T_1f77f_row2_col0\" class=\"data row2 col0\" >            expr_list.append(expr_s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f77f_level0_row3\" class=\"row_heading level0 row3\" >15500</th>\n",
       "      <td id=\"T_1f77f_row3_col0\" class=\"data row3 col0\" >        self.config_fixture.config(group='cache', enabled=True).1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1f77f_level0_row4\" class=\"row_heading level0 row4\" >37765</th>\n",
       "      <td id=\"T_1f77f_row4_col0\" class=\"data row4 col0\" >            report_doc.updated_on = datetime.datetime.now(tz=bson.tz_util.utc)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d4793e890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_219c7\">\n",
       "  <caption>synthetic</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_219c7_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_219c7_level0_row0\" class=\"row_heading level0 row0\" >90144</th>\n",
       "      <td id=\"T_219c7_row0_col0\" class=\"data row0 col0\" >(p(h(j(V)l)q(R)F(H)n(e(S(m(k)w(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_219c7_level0_row1\" class=\"row_heading level0 row1\" >2681</th>\n",
       "      <td id=\"T_219c7_row1_col0\" class=\"data row1 col0\" >(u)q(A(p(w(b(T(H)l)K)k(r(b)y)C)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_219c7_level0_row2\" class=\"row_heading level0 row2\" >61912</th>\n",
       "      <td id=\"T_219c7_row2_col0\" class=\"data row2 col0\" >(X)C(T(u(j)K(i(U)E(v)Y)T)r)o(g(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_219c7_level0_row3\" class=\"row_heading level0 row3\" >51794</th>\n",
       "      <td id=\"T_219c7_row3_col0\" class=\"data row3 col0\" >(v(X)Q)x(K(S(V)z)F(P)r(f(b(y(h(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_219c7_level0_row4\" class=\"row_heading level0 row4\" >16530</th>\n",
       "      <td id=\"T_219c7_row4_col0\" class=\"data row4 col0\" >(o(T(N)c)w)C(l)h(x)e(u(S(e(e)n(</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d4793f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = {}\n",
    "for name, dataset_filename in DATA_FILES.items():\n",
    "    df = pd.read_csv(dataset_filename)\n",
    "    df = df.sample(frac=1, random_state=SEED)\n",
    "    df = df[:DATASET_MAX_SIZE]\n",
    "    datasets[name] = df\n",
    "    display(datasets[name].head().style.set_caption(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_datasets = {}\n",
    "for name, dataset in datasets.items():\n",
    "    tokenised_datasets[name] = model.to_tokens(\n",
    "        dataset[\"text\"].values, move_to_device=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_line torch.Size([10000, 118])\n",
      "synthetic torch.Size([10000, 32])\n"
     ]
    }
   ],
   "source": [
    "for name, dataset in tokenised_datasets.items():\n",
    "    print(name, dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model predictions on single_line: 100%|██████████| 157/157 [05:13<00:00,  1.99s/it]\n",
      "Model predictions on synthetic: 100%|██████████| 157/157 [01:09<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "if LOAD_MODEL_PREDICTIONS:\n",
    "    model_predictions = torch.load(MODEL_PREDICTIONS_DATA_FILE)\n",
    "else:\n",
    "    model_predictions = {}\n",
    "    for name, dataset in tokenised_datasets.items():\n",
    "        model_predictions[name] = torch.empty(\n",
    "            tokenised_datasets[name].shape, dtype=torch.int8\n",
    "        )\n",
    "        for batch_start in tqdm(\n",
    "            range(0, len(dataset), MODEL_BATCH_SIZE), desc=f\"Model predictions on {name}\"\n",
    "        ):\n",
    "            batch_slice = slice(batch_start, batch_start + MODEL_BATCH_SIZE)\n",
    "            batch = dataset[batch_slice].to(device)\n",
    "            with torch.no_grad():\n",
    "                model_output = output_modifier(model(batch)).argmax(dim=-1)\n",
    "            model_predictions[name][batch_slice] = model_output\n",
    "\n",
    "if SAVE_MODEL_PREDICTIONS:\n",
    "    torch.save(model_predictions, MODEL_PREDICTIONS_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DAG predictions for basic on single_line:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DAG predictions for basic on single_line: 100%|██████████| 1/1 [00:00<00:00, 33.44it/s]\n",
      "DAG predictions for basic on synthetic: 100%|██████████| 1/1 [00:00<00:00, 132.88it/s]\n"
     ]
    }
   ],
   "source": [
    "dag_predictions = {}\n",
    "for dag_name, dag in dags.items():\n",
    "    dag_predictions[dag_name] = {}\n",
    "    for dataset_name, dataset in tokenised_datasets.items():\n",
    "        dag_predictions[dag_name][dataset_name] = torch.empty(\n",
    "            tokenised_datasets[dataset_name].shape, dtype=torch.int8\n",
    "        )\n",
    "        for batch_start in tqdm(\n",
    "            range(0, len(dataset), DAG_BATCH_SIZE),\n",
    "            desc=f\"DAG predictions for {dag_name} on {dataset_name}\",\n",
    "        ):\n",
    "            batch_slice = slice(batch_start, batch_start + DAG_BATCH_SIZE)\n",
    "            batch = dataset[batch_slice].to(device)\n",
    "            dag_output = dag(dict(x=batch))[\"c\"]\n",
    "            dag_predictions[dag_name][dataset_name][batch_slice] = dag_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_accurcies = np.empty((len(dags), len(datasets)))\n",
    "for i, (dag_name, dag) in enumerate(dags.items()):\n",
    "    for j, (dataset_name, dataset) in enumerate(datasets.items()):\n",
    "        dag_accurcies[i, j] = (\n",
    "            (dag_predictions[dag_name][dataset_name] == model_predictions[dataset_name])\n",
    "            .to(torch.float32)\n",
    "            .mean()\n",
    "            .item()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">              DAG accuracies               </span>\n",
       "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> DAG \\ Dataset </span>┃<span style=\"font-weight: bold\"> single_line </span>┃<span style=\"font-weight: bold\"> synthetic </span>┃\n",
       "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ basic         │ 36.28%      │ 43.54%    │\n",
       "└───────────────┴─────────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m              DAG accuracies               \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mDAG \\ Dataset\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msingle_line\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msynthetic\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ basic         │ 36.28%      │ 43.54%    │\n",
       "└───────────────┴─────────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(title=\"DAG accuracies\", show_header=True, header_style=\"bold\")\n",
    "table.add_column(\"DAG \\\\ Dataset\")\n",
    "for dataset_name in datasets.keys():\n",
    "    table.add_column(dataset_name)\n",
    "for i, dag_name in enumerate(dags.keys()):\n",
    "    table.add_row(dag_name, *[f\"{dag_accurcies[i, j]:.2%}\" for j in range(len(datasets))])\n",
    "    \n",
    "console = Console()\n",
    "console.print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
